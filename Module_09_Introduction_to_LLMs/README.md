# Large Language Models

## Topics covered in today's module
* Introduction to Large Language Models
* Introduction to Transformers
* Prompting
* Decoding and Objective of the Transformers
* Self-Attention

## Main takeaways from doing today's assignment
I learned about optimal prompting practices, the decoding process of LLMs, transformers, and self-attention. I was also introduced to pre-training, in-context learning, fine-tuning, and instruction-tuning.

## Challenging, interesting, or exciting aspects of today's assignment
It was interesting to be exposed to the inner workings of large language models.

## Additional resources
1. Did you need to use tools like AI tools ChatGPT or Gemini to answer any of the questions or learn any of the concepts in this notebook? If  yes, state for which questions or concepts did you require Generative AI tools? 

    I did not use such tools to provide answers to or learn any concepts for any question. I only used ChatGPT for the questions asking me to try prompts in a LLM of my choice.

2. If you answered "yes" to Question #1, which part of the answers are written by you, and which part of the answers are written by an AI tool? 

    Not applicable.

3. If you answered "yes" to Question #1, after using the AI tool to gain a better understanding of the material in this notebook, summarize your learnings here.

    Not applicable.

4. Did you use any other resources besides AI tools?

    No.
